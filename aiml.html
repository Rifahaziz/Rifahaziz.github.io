<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Theme Made By www.w3schools.com - No Copyright -->
    <title>Rifah's Projects</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
    <style>
        body {
            font: 20px Montserrat, sans-serif;
            line-height: 1.8;
            color: #ADADAD /*#f5f6f7;*/
        }

        p {
            font-size: 16px;
        }

        .margin {
            margin-bottom: 45px;
        }

        .bg-1 {
            background-color: #CEBEBE;
            #6D2E46;
            #A46E7F;
            #9E5A63;
            color: #000000;
        }

        .bg-2 {
            background-color: #E4E1DB;
            #F3EDE2;
            #A26769;
            #644E5B;
            color: #000000;
        }

        .bg-3 {
            background-color: #ffffff;
            color: #000000;
        }

        .bg-4 {
            background-color: #D5B9B2;
            #ECE2D0;
            #97AABD;
            color: #000000;
        }

        .bg-5 {
            background-color: #D5B9B2;
            #987689;
            color: #000000;
        }

        .container-fluid {
            padding-top: 70px;
            padding-bottom: 70px;
        }

        .navbar {
            padding-top: 15px;
            padding-bottom: 15px;
            border: 0;
            border-radius: 0;
            margin-bottom: 0;
            font-size: 15px;
            letter-spacing: 5px;
        }

        .navbar-nav li a:hover {
            color: #19E5A63 !important; /*1ABC9C*/
        }

        .fa-instagram {
            background: #bb173a;
            color: white;
        }

        .fa-linkedin {
            background: #007bb5;
            color: white;
        }

        .fa:hover {
            opacity: 0.7;
        }

        .fa-facebook {
            background: #3B5998;
            color: white;
        }

        .fa-google {
            background: #dd4b39;
            color: white;
        }

        .fa {
            padding: 10px;
            font-size: 20px;
            width: 40px;
            text-align: center;
            text-decoration: none;
            margin: 0;
            border-radius: 50%;
        }
    </style>
</head>
<body>

    <!-- Navbar -->
    <nav class="navbar navbar-default">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="index.html">Home</a>
            </div>
            <div class="collapse navbar-collapse" id="myNavbar">
                <ul class="nav navbar-nav navbar-right">
                    <li><a href="aiml.html">AI/ML </a></li>
                    <li><a href="hci.html">HCI</a></li>
                    <!-- <a href="https://rifahswork.wordpress.com/">Masters </a></li>  david mould's work-->
                    <li><a href="projects.html">Web </a></li>
                    <!-- <li><a href="personalprojects.html">Personal </a></li>-->
                    <li><a href="art.html">Art</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- First Container -->
    <div class="container-fluid  text-left bg-1">
        <h3 class="text-center"> What I've Learned During my Masters </h3> <br>
        <hr width="100%;"
            color="red"
            size="10"
            align="left">

        <div class=" partition">
            <div class="col-sm-5">
                <img src="images/validate_0.png" class="text-right framepic" width="100%" />
                <img src="images/validate_1.png" class="text-right framepic" width="100%" />
            </div>

            <div class="text-left webpartition  col-sm-7">
                <h3> RGB-D Fusion for Segmentation on Indoor data for Autonomous Wheelchair  </h3>
                <p>
                    Research Project - Worked on image+depth fusion techniques with transformer networks and with traditional YOLOV7 for segmentation
                    on indoor dataset used for autonomous wheelchair scenario <br />
                </p>

                <h5>*Code cannot be viewed due to privacy concerns from Professor</h5>
                <br />
                <br />
            </div>
        </div>

        <hr width="100%;"
            color="red"
            size="10"
            align="left">


        <div class="partition">
            <div class="text-right   col-sm-5">
                <img src="images/gan.png" class="text-right framepic" width="100%" />
               
             </div>
             <div class="text-left webpartition  col-sm-7">
                <h3>GANs (Generative Adversarial Networks) on Limited Data </h3>
                <p>
                    Explored ways to overcome the problem of limited data by using various GAN methods to increase the dataset by synthetically creating new but similar data.
                </p>
                <button class="btn btn-secondary" type="button"> <a class="visiblefont" href="https://github.com/Rifahaziz/GANs_on_limited_data.git" target="_blank">View on Github </a></button> <br><br>




              </div>
            <br />


        </div>
        <br />
        <hr width="100%;"
            color="red"
            size="10"
            align="left">


        <div class="partition">
            <div class="text-right   col-sm-9">
                <h3> Maze-Ro Puzzle Game with Procedural Content Generation (PCG) </h3>
                <p>
                    Used procedural rule generation to randomly create rules and check its fitness through genetic algorithm. This was a team project of two people.
                    My portion of the work was the rule generation through genetic algorithm in C# while my teammate worked on creating the display and scene in unity.

                </p>
                <img src="images/maze.png" class="text-center framepic" width="80%" /> <br />
                <button class="btn btn-secondary " type="button"><a class="visiblefont text-center" href="https://github.com/kristen223/ITEC-5203-Chromatic-Maze/tree/main/5203-Chromatic-Maze/Assets/Scripts/Rifah" target="_blank"> View on GitHub</a> </button>
            </div>



            <div class="col-sm-3">
                <img src="images/maze flowchart.png" class="text-center framepic " width="80%" /> <br>
            </div>
            <br />


        </div>
        <br />
        <hr width="100%;"
            color="red"
            size="10"
            align="left">



        <div class=" partition">
            <div class="col-sm-5">
                <img src="images/imgsty.jpg" class="text-center framepic " width="100%" />
            </div>

            <div class="text-left webpartition  col-sm-7">
                <h3> Artistic Images with Dijsktra's Algorithm </h3>
                <p>
                    Inspired by the various elements in rocks and stones, used Dijkstra's algorithm to create artistic images
                    from a graph structure....
                    ...
                    ..
                    <br />
                    <br /> <br /> <br /> <br /> <br />
                </p>
                <img src="images/imgsty1.png" class="text-right framepic" width="23%" />
                <img src="images/m4s.png" class="text-right framepic" width="23%" />
                <img src="images/imgsty2.png" class="text-right framepic" width="23%" />
                <img src="images/imgsty3.png" class="text-right framepic" width="23%" />
                <br />
                <button class="btn btn-secondary" type="button"><a class="visiblefont" href="https://github.com/Rifahaziz/Artistic_Images_with_Dijkstra.git" target="_blank"> View on GitHub</a> </button>
            </div>
        </div>
        <br />
        <hr width="100%;"
            color="red"
            size="10"
            align="left">















        <!--<div class=" artition">
        <div class="text-left   col-sm-4">
            <h3> Maze-Ro Puzzle Game with Procedural Content Generation (PCG) </h3>
            <p>
                Used procedural rule generation to randomly create rules and check its fitness through genetic algorithm. This was a team project of two people.
                My portion of the work was the rule generation through genetic algorithm in C# while my teammate worked on creating the display and scene in unity.

                <br />
                <br /> <br /> <br /> <br /> <br />
            </p>
            <img src="images/maze.png" class="text-right framepic" width="20%" />

            <button class="btn btn-secondary" type="button"><a class="visiblefont" href="https://github.com/kristen223/ITEC-5203-Chromatic-Maze/tree/main/5203-Chromatic-Maze/Assets/Scripts/Rifah" target="_blank"> View on GitHub</a> </button>
        </div>

        <div class="col-sm-5">
            <img src="images/maze flowchart.png" class="text-center framepic " width="50%" />
        </div>


    </div>-->






            <!------------------------DEEPLEARNING.AI ------------------------->
            <div class="container-fluid bg-2 text-left">
                <h3 class="text-center"> What I've Learned from DeepLearning.ai Specialization </h3> <br>
                <ul>
                    <div class="text-left webpartition col-sm-6">
                    <li><h3> Emotion Detection Model </h3></li>
                    <p>
                        A model built with CNN that detects if a person is happy based on their smiles. This is the first time I have used Keras in Python. The train accuracy is 99% while test accuracy is 97%. <br>
                        Training set = 600 pictures of size (600,64,64,3) <br> and
                        Test-set = 150 pictures of size (10,64,64,3) <br>
                        <br>
                    </p>
                    <button class="btn btn-secondary" type="button">
                        <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/Emotion%20Detection" target="_blank"> View on Github</a>
                    </button>
                    <br />
                    <br />

                    <li><h3>Face Recognition Model</h3></li>
                    <p>
                        What's the difference between face verification and recognition?<br>
                        Face verification is a simpler task that involves matching the input image with the claimed person's image. It is a 1:1 matching problem! <br>
                        However, face recognition is a bit more complex. It is matching a given input image across a database of images to find who the particular individual
                        is. It is a 1:K matching problem! <br>
                        <br />
                        Both face recognition and verification are applied here with triplet loss function and a pre-trained model to map face images into 128-dimensional
                        encodings. Numpy,Keras, Tensorflow, pandas, cv2 are used to build this model.

                    </p>
                    <button class="btn btn-secondary" type="button">
                        <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/Face%20Recognition" target="_blank"> View on Github</a>
                    </button>
                    <br>
                    <br>
                    <br />
                    <br />


            </div>
            <div class="col-sm-1"></div>
            <div class=" webpartition col-sm-6 text-left">
                <li><h3> Neural Style Transfer</h3></li>
                <p>
                    I absolutely <strong>LOVE</strong> this project as it generates ART with neural networks.
                    Neural Style Transfer algorithm is used to merge an image's content with another image's style to output unique styled art. A pre-trained model is used to do this task <br>
                    Content cost function is used using tensorflow. Style cost is computed using Style Matrix( Gram Matrix) and Style Weights. Total cost is the addition of these costs with added weights and Adam optimizer is used. <br>
                    Libraries used are matplotlib, numpy, pprint, scipy,tensorflow, PIL, etc. <br><br>

                </p>
                <button class="btn btn-secondary" type="button"> <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/Neural%20Style%20Transfer" target="_blank">View on Github </a></button> <br><br>

                <li><h3>Autonomous Driving using YOLO algorithm</h3> </li>
                <p>
                    Here, we are mainly creating object detection on a car detection dataset and dealing with bounding boxes

                    <br> <br>
                    Libraries used : keras,numpy,scipy,matplotlib, tensorflow, pandas,PIL
                    <br><br>
                    "You Only Look Once" (YOLO) performs object detection, and then can be applied it to car detection. As YOLO model is very computationally expensive to train, we have loaded pre-trained weights. It is a popular algorithm because it achieves high accuracy while also being able to run in real-time. This algorithm "only looks once" at the image in the sense that it requires only one forward propagation pass through the network to make predictions. After non-max suppression, it then outputs recognized objects together with the bounding boxes.
                    <br>
                    The YOLO architecture is: IMAGE (m, 608, 608, 3) -> DEEP CNN -> ENCODING (m, 19, 19, 5, 85). <br><br>

                    The input is a batch of images, and each image has the shape (m, 608, 608, 3)
                    The output is a list of bounding boxes along with the recognized classes.  <br>

                    Anchor boxes are chosen by exploring the training data to choose reasonable height/width ratios that represent the different classes. <br>

                    <br>

                </p>

                <button class="btn btn-secondary" type="button">
                    <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/YOLO%20algorithm" target="_blank"> View on Github</a>
                </button> <br><br>
            </div>
            </ul>
        </div>






        <!-- First Container
    <div class="container-fluid bg-1 ">
        <h2 class="text-center display-3 font-italic"> My Own Projects </h2> <br>
    </div>

    <div class="container-fluid ">

        <div class=" partition space  bg-7">
            <h3 class="text-center"> Emotion Detection Model </h3>
            <p>
                A model built with CNN that detects if a person is happy based on their smiles. This is the first time I have used Keras in Python. The train accuracy is 99% while test accuracy is 97%. <br>
                Training set = 600 pictures of size (600,64,64,3) <br> and
                Test-set = 150 pictures of size (10,64,64,3) <br>
                <br>
                Help taken from the deeplearning.ai course by Andrew Ng on Coursera. <br>
            </p>

            <button class="btn btn-secondary" type="button">
                <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/Emotion%20Detection" target="_blank"> View on Github</a>
            </button> <br><br>

            <div class="text-left  col-sm-6">
                <img src="" class="text-right framepic" height="350px">
            </div>
        </div>

        <div class=" partition space bg-6">
            <h3 class="text-center"> Face Recognition Model </h3>
            <p>
                What's the difference between face verification and recognition?<br>
                Face verification is a simpler task that involves matching the input image with the claimed person's image. It is a 1:1 matching problem! <br>
                However, face recognition is a bit more complex. It is matching a given input image across a database of images to find who the particular individual is. It is a 1:K matching problem! <br>
            <p>
            <p>
                Both face recognition and verification are applied here with triplet loss function and a pre-trained model to map face images into 128-dimensional encodings. Numpy,Keras, Tensorflow, pandas, cv2 are used to build this model.

                <br> <br>
                Programming assignment from the deeplearning.ai course by Andrew Ng on Coursera. <br>
            </p>

            <button class="btn btn-secondary" type="button">
                <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/Face%20Recognition" target="_blank"> View on Github</a>
            </button> <br><br>

            <div class="text-left  col-sm-6">
                <img src="" class="text-right framepic" height="350px">
            </div>
        </div>

        <div class=" partition space  bg-5">
            <h3 class="text-center"> Neural Style Transfer </h3>
            <p>
                I absolutely <strong>LOVE</strong> this project as it generates ART with neural networks.
                Neural Style Transfer algorithm is used to merge an image's content with another image's style to output unique styled art. A pre-trained model is used to do this task <br>
                Content cost function is used using tensorflow. Style cost is computed using Style Matrix( Gram Matrix) and Style Weights. Total cost is the addition of these costs with added weights and Adam optimizer is used. <br>
                Libraries used are matplotlib, numpy, pprint, scipy,tensorflow, PIL, etc. <br><br>



                Programming assignment from the deeplearning.ai course by Andrew Ng on Coursera. <br>
            </p>

            <button class="btn btn-secondary" type="button">
                <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/Neural%20Style%20Transfer" target="_blank"> View on Github</a>
            </button> <br><br>

            <div class="text-left  col-sm-6">
                <img src="" class="text-right framepic" height="350px">
            </div>
        </div>

        <div class=" partition space bg-8">
            <h3 class="text-center"> Autonomous Driving using YOLO algorithm</h3>
            <p>
                Here, we are mainly creating object detection on a car detection dataset and dealing with bounding boxes

                <br> <br>
                Libraries used : keras,numpy,scipy,matplotlib, tensorflow, pandas,PIL, argparse
                <br><br>
                "You Only Look Once" (YOLO) performs object detection, and then can be applied it to car detection. As YOLO model is very computationally expensive to train, we have loaded pre-trained weights. It is a popular algorithm because it achieves high accuracy while also being able to run in real-time. This algorithm "only looks once" at the image in the sense that it requires only one forward propagation pass through the network to make predictions. After non-max suppression, it then outputs recognized objects together with the bounding boxes.
                <br>
                The YOLO architecture is: IMAGE (m, 608, 608, 3) -> DEEP CNN -> ENCODING (m, 19, 19, 5, 85). <br><br>

                The input is a batch of images, and each image has the shape (m, 608, 608, 3)
                The output is a list of bounding boxes along with the recognized classes.  <br>

                Anchor boxes are chosen by exploring the training data to choose reasonable height/width ratios that represent the different classes. <br>

                <br>
                Programming assignment from the deeplearning.ai course by Andrew Ng on Coursera. <br>
            </p>

            <button class="btn btn-secondary" type="button">
                <a class="visiblefont" href="https://github.com/Rifahaziz/deeplearning.ai-coursera/tree/main/4.%20Convolutional%20Neural%20Networks/YOLO%20algorithm" target="_blank"> View on Github</a>
            </button> <br><br>

            <div class="text-left  col-sm-6">
                <img src="" class="text-right framepic" height="350px">
            </div>
        </div>-->
        </li>
    </div>

    <div class="container-fluid bg-5 text-center">
        <h3> Undergrad Thesis</h3>

        <div class="text-cent webpartition " id="thesis">

            <h4> Building A Credit Scoring Model To Assign A Reference Score Based On Credit Transaction And Relevant Profile Data</h4>

            <p>Thesis work done under the supervision of Dr.Mahbub Alam Majumdar and Md.Saiful Islam.</p>

            <a href="https://drive.google.com/open?id=1TLEH771wYBEKIXcAXxeSBVY2HZC8-_FT" class=" text-right" target="_blank">
                <img class="framepic" src="images/RFDNN.jpg" width=60% />
                <br />


                <button class="btn btn-secondary" type="button"><a class="visiblefont" href="https://www.researchgate.net/publication/336141440_Building_A_Credit_Scoring_Model_To_Assign_A_Reference_Score_Based_On_Credit_Transaction_And_Relevant_Profile_Data" target="_blank"> Full Paper</a></button>
                <button class="btn btn-secondary" type="button"> <a class="visiblefont" href="https://github.com/Rifahaziz/Credit-Scoring-Model-.git" target="_blank">View on Github </a></button> <br>
                </li>
        </div>


        </a>



    </div>










    <!-- Third Container (Grid) -->
    <!-- Footer -->
    <!-- Footer -->
    <footer id="footer" class="container-fluid bg-3 text-center">
        <div style="float:left">
            <a href="https://www.linkedin.com/in/rifahsamaaziz/" class="fa fa-linkedin"></a>
            <a href="https://www.instagram.com/rifah_aziz/" class="fa fa-instagram"></a>
            <a href="https://www.facebook.com/rifah.aziz05/" class="fa fa-facebook"></a>
            <a href="mailto: rifahz999@gmail.com" class="fa fa-google"></a>

        </div>

        <div style="float: right">
            <small> &copy; 2019 Rifah Sama Aziz</small>
        </div>

    </footer>

</body>
</html>
